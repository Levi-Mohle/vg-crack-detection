_target_: src.models.denoisingdiffusion_module.DenoisingDiffusionLitModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.0002
  weight_decay: 0.0

# scheduler:
#   _target_: torch.optim.lr_scheduler.StepLR
#   _partial_: true
#   step_size: 1
#   gamma: 0.99
scheduler:
  _target_: src.models.components.scheduler.schedulers.WarmupCosineScheduler
  _partial_: true
  num_warmup_steps: 40
  num_training_steps: ${data.batch_size}
  num_cycles: 0.5

criterion:
  _target_: src.models.components.loss_functions.losses.SSIM_loss

noise_scheduler:
  _target_: diffusers.schedulers.DDPMScheduler
  num_train_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: linear
  trained_betas: null
  variance_type: fixed_small
  clip_sample: false
  prediction_type: epsilon
  thresholding: false
  dynamic_thresholding_ratio: 0.995
  clip_sample_range: 1.0
  sample_max_value: 1.0
  timestep_spacing: leading
  steps_offset: 0
  rescale_betas_zero_snr: false

# unet:
#   _target_: diffusers.models.UNet2DModel
#   act_fn: silu
#   add_attention: true
#   attention_head_dim: 8
#   attn_norm_num_groups: null
#   center_input_sample: false
#   class_embed_type: null
#   block_out_channels:
#     - 128
#     - 128
#     - 256
#     - 256
#     - 512
#     - 512
#   down_block_types:
#     - DownBlock2D
#     - DownBlock2D
#     - DownBlock2D
#     - DownBlock2D
#     - AttnDownBlock2D
#     - DownBlock2D
#   up_block_types:
#     - UpBlock2D
#     - AttnUpBlock2D
#     - UpBlock2D
#     - UpBlock2D
#     - UpBlock2D
#     - UpBlock2D
#   downsample_padding: 1
#   downsample_type: conv
#   dropout: 0.0
#   flip_sin_to_cos: true
#   freq_shift: 0
#   in_channels: 3
#   layers_per_block: 2
#   mid_block_scale_factor: 1
#   norm_eps: 1.0e-05
#   norm_num_groups: 32
#   num_class_embeds: null
#   num_train_timesteps: null
#   out_channels: ${model.unet.in_channels}
#   resnet_time_scale_shift: default
#   sample_size: 32
#   time_embedding_type: positional
#   upsample_type: conv
unet:
  _target_: src.models.components.u_net.UNetModel
  image_size : 512
  in_channels : 2
  model_channels: 64
  out_channels : 2
  num_res_blocks : 2
  attention_resolutions : [4]
  dropout : 0.0
  channel_mult : [1, 2, 2, 4]
  conv_resample : true
  dims : 2
  n_classes : null
  use_checkpoint : false
  use_fp16 : false
  num_heads : 1
  num_head_channels :  -1
  num_heads_upsample : -1
  use_scale_shift_norm : false
  resblock_updown : false
  use_new_attention_order : false

DDPM_param:
    mode: both
    target: 2
    reconstruct: .05
    wh: 1
    plot_n_epoch: 5
    plot_ids: [0,1,16,17]
    encode: false
    pretrained_dir: 'C:\Users\lmohle\Documents\2_Coding\data\Trained_Models\AutoEncoderKL\'
    ood: false
    max_epochs: ${trainer.max_epochs}
    batch_size: ${data.batch_size}
    use_cond: false
    condition_weight: 2
    skip_steps: 25
    eta: 1
    save_reconstructs: false
    plot: false
    win_size: 5
    
compile: false

paths: 
  log_dir: ${paths.output_dir}