_target_: src.models.ddpm_module.DenoisingDiffusionLitModule

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.0002
  weight_decay: 0.0

# scheduler:
#   _target_: torch.optim.lr_scheduler.StepLR
#   _partial_: true
#   step_size: 1
#   gamma: 0.99
scheduler:
  _target_: src.models.components.scheduler.schedulers.WarmupCosineScheduler
  _partial_: true
  num_warmup_steps: 500
  num_training_steps: 6400
  num_cycles: 0.5

criterion:
  _target_: src.models.components.loss_functions.losses.SSIM_loss

noise_scheduler:
  _target_: diffusers.schedulers.DDPMScheduler
  num_train_timesteps: 1000
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: linear
  trained_betas: null
  variance_type: fixed_small
  clip_sample: false
  prediction_type: epsilon
  thresholding: false
  dynamic_thresholding_ratio: 0.995
  clip_sample_range: 1.0
  sample_max_value: 1.0
  timestep_spacing: leading
  steps_offset: 0
  rescale_betas_zero_snr: false

unet:
  _target_: diffusers.models.UNet2DModel
  act_fn: silu
  add_attention: true
  attention_head_dim: 8
  attn_norm_num_groups: null
  center_input_sample: false
  class_embed_type: null
  block_out_channels:
    - 128
    - 128
    - 256
    - 256
    - 512
    - 512
  down_block_types:
    - DownBlock2D
    - DownBlock2D
    - DownBlock2D
    - DownBlock2D
    - AttnDownBlock2D
    - DownBlock2D
  up_block_types:
    - UpBlock2D
    - AttnUpBlock2D
    - UpBlock2D
    - UpBlock2D
    - UpBlock2D
    - UpBlock2D
  downsample_padding: 1
  downsample_type: conv
  dropout: 0.0
  flip_sin_to_cos: true
  freq_shift: 0
  in_channels: 3
  layers_per_block: 2
  mid_block_scale_factor: 1
  norm_eps: 1.0e-05
  norm_num_groups: 32
  num_class_embeds: null
  num_train_timesteps: null
  out_channels: 3
  resnet_time_scale_shift: default
  sample_size: 32
  time_embedding_type: positional
  upsample_type: conv

compile: false

reconstruct_coef: .2

target: 2

paths: 
  log_dir: ${paths.output_dir}