# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: impasto
  - override /model: flowmatching
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["impasto", "conditonal flow matching", "optimal transport",
        "classifier free guidance"]

seed: 12345

callbacks:
    early_stopping:
        monitor: "val/loss"
        patience: 10
        mode: "min"
    model_summary:
      max_depth: 1
    model_checkpoint:
        mode: "min"
        monitor: "val/loss"

model:
    optimizer:
      lr: 1e-5
    unet:
      _target_: diffusers.models.UNet2DConditionModel
      in_channels: 2
      out_channels: 2
      attention_head_dim: 8
      num_class_embeds: 128
      class_embed_type: null
    FM_param:
      latent: false
      pretrained: '/data/storage_crack_detection/Pretrained_models/AutoEncoderKL/'
      step_size: 0.01
      method: ot
      CFG: true
      reconstruct: 0.3
      save_reconstructs: false
      plot_n_epoch: 50
      target: 2
      solver_lib: torchdiffeq
      mode: both
      wh: 1
      plot_ids: [0,1,5,6]
      ood: false
      win_size: 5
  
trainer:
  min_epochs: 5
  max_epochs: 40
  enable_model_summary: false
  gradient_clip_val: 0.5

data:
    variant: 32x32
    crack: synthetic
    batch_size: 32
    rgb_transform: 
        _target_: src.data.components.transforms.diffuser_to_grayscale
    height_transform:
        _target_: src.data.components.transforms.diffuser_normalize_height_idv

extras:
  print_config: false

logger:
  csv:
      prefix: "impasto_flowmatching"
  wandb:
    tags: ${tags}
    group: "impasto"
  aim:
    experiment: "impasto"
  mlflow:
    experiment_name: "impasto flowmatching"
  tensorboard:
    name: "impasto flowmatching"

