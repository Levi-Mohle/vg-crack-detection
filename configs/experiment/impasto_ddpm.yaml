# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /data: impasto
  - override /model: ddpm
  - override /callbacks: default
  - override /trainer: default

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["impasto", "conditional denoising diffusion"]

seed: 12345

callbacks:
    early_stopping:
        monitor: "val/loss"
        patience: 50
        mode: "min"
    model_summary:
      max_depth: 1
    model_checkpoint:
        mode: "min"
        monitor: "val/loss"

model:
    criterion:
      _target_: src.models.components.loss_functions.losses.MSE_loss
    optimizer:
      lr: 1e-5
    unet:
      image_size : 64
      in_channels : 8
      model_channels: 128 
      out_channels : 8
      num_res_blocks : 2
      attention_resolutions : [16]
      dropout : 0.0
      channel_mult : [1, 1, 2, 2, 4, 4]
      n_classes : null
    noise_scheduler:
      num_train_timesteps: 1000
    scheduler:
      _target_: src.models.components.scheduler.schedulers.WarmupCosineScheduler
      _partial_: true
      num_warmup_steps: 500
      num_training_steps: 6400
      num_cycles: 0.5
    # scheduler:
    #   _target_: torch.optim.lr_scheduler.StepLR
    #   _partial_: true
    #   step_size: 1
    #   gamma: 0.99
    DDPM_param:
      mode: both
      target: 2
      reconstruct: .2
      wh: 1
      plot_n_epoch: 20
      plot_ids: [1,5,6]
      encode: true
      pretrained: '/data/storage_crack_detection/Pretrained_models/AutoEncoderKL'
      ood: true
      use_cond: false
      condition_weight: 2
      skip_steps: 25
      eta: 1
      save_reconstructs: false
      plot: true
    
trainer:
  min_epochs: 5
  max_epochs: 300
  enable_model_summary: false
  gradient_clip_val: 0.5

data:
  batch_size: 32
  variant: Enc_512x512
  crack: synthetic
  transform: null
      # _target_:

extras:
  print_config: false

logger:
  csv:
      prefix: "impasto_ddpm"
  wandb:
    tags: ${tags}
    group: "impasto"
  aim:
    experiment: "impasto"
  mlflow:
    experiment_name: "impasto ddpm"
  tensorboard:
    name: "impasto ddpm"

